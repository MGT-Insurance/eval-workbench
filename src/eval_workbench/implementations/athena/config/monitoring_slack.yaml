# Monitoring configuration for Athena Slack composite monitoring
version: "1.0"
name: "athena_slack_monitor"
environment: "${ENVIRONMENT:-production}"

# Scored items store (deduplication)
scored_store:
  type: db

# Data source configuration
source:
  type: slack_neon_join
  db_source_type: "slack"
  name: "athena"
  window_minutes: 10000
  component: "recommendation"
  eval_mode: "online"
  environment: "${ENVIRONMENT:-production}"
  channel_ids:
    - "C09MAP9HR9D" # specialty-referrals
    - "C09JE5SSP43" # referrals
  limit: 100 # Max messages per channel
  scrape_threads: true # Include thread replies
  bot_names: ["Athena"] # Names used to identify AI vs human messages
  workspace_domain: "mgtinsurance" # Slack workspace subdomain
  drop_if_first_is_user: true
  drop_if_all_ai: true # Keep all-AI threads; composite now handles zero-human safely
  max_concurrent: 2 # Max concurrent channel scrapes
  exclude_senders: ["Prometheus"]
  drop_message_regexes:
    - "^Street View"
    - "google\\.com/maps"
    - "intercom: Intercom Conversation"
  strip_citation_block: true
  member_id_to_display_name:
    U09JKDU4RE2: "Athena"
  human_mention_token: "@human"
  use_slack_thread_dataset_id: true # id format: slack-{channel_id}-{thread_ts}

  # Neon join configuration
  neon_query: |
    SELECT
      slack_thread_ts,
      slack_channel_id,
      quote_locator,
      langfuse_trace_id AS trace_id,
      created_at
    FROM athena_cases
  slack_join_columns: ["channel_id", "thread_ts"]
  neon_join_columns: ["slack_channel_id", "slack_thread_ts"]
  neon_time_column: "created_at"
  buffer_minutes: 30

# Sampling strategy: controls which items get evaluated from fetched pool
# Available strategies: all, random, most_recent, oldest
sampling:
  strategy: most_recent
  n: 5
  seed: 42

# Metrics configuration
metrics_config:
  SlackHeuristic:
    class: "slack_heuristic_analyzer"
  UnderwritingComposite:
    class: "underwriting_composite_evaluator"
    llm_provider: "openai"
    model_name: "gpt-5.2"
    config:
      bot_name: "Athena assistant"
      domain_context: "Commercial Insurance Underwriting (Platform: Socotra/SFX, Data: Magic Dust)"

# Evaluation runner configuration
evaluation:
  max_concurrent: 2
  throttle_delay: 5
  metadata:
    eval_mode: "online"
    schedule: "manual_or_scheduler"
    source_window_minutes: 300
    pipeline_version: "athena_slack_composite_v1"
    run_initiator: "monitor"

# Publishing configuration
publishing:
  push_to_db: false
  push_to_langfuse: false # Always should be False for Slack
  # Whether to trace evaluation runs in Langfuse (creates observation traces)
  trace_experiment: false

  # Database upload configuration (used when push_to_db: true)
  database:
    on_conflict: do_nothing  # do_nothing | upsert | error
    chunk_size: 1000         # Rows per batch upload

  experiment:
    enabled: false # More than likely not needed for Slack
